{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQLfs9cgC6l-"
      },
      "outputs": [],
      "source": [
        "# ejemplo tomado de: \n",
        "# https://community.hortonworks.com/articles/84781/spark-text-analytics-uncovering-data-driven-topics.html\n",
        "# github: https://github.com/zaratsian/Spark/blob/master/text_analytics_datadriven_topics.json (con zeppelin)\n",
        "# otros ejemplos muy buenos: https://github.com/zaratsian/Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUVs2VCYBkVe",
        "outputId": "e1dca687-f3b1-4b95-9968-a75c14b7aaa3"
      },
      "outputs": [],
      "source": [
        "#configuraci贸n en google colab de spark y pyspark\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#configuraci贸n en google colab\n",
        "#instalar java y spark\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.5.2/spark-3.5.2-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.2-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.2-bin-hadoop3\"\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjW7J3n9C6mH"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "#forma 1 de crear la sesi贸n y el contexto Spark:\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "\n",
        "#forma 2 de crear la sesi贸n y el contexto Spark:\n",
        "#sc = SparkContext.getOrCreate()\n",
        "#spark=SparkSession.builder.appName('nlp').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNHKHUNSC6mD"
      },
      "outputs": [],
      "source": [
        "#from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import monotonically_increasing_id, col, expr, when, concat, lit, isnan\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.regression import GeneralizedLinearRegression\n",
        "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n",
        "from pyspark.ml.feature import VectorIndexer, VectorAssembler, StringIndexer, OneHotEncoder\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, RegressionEvaluator, BinaryClassificationEvaluator\n",
        "from pyspark.ml import Pipeline\n",
        "import pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2Cz07ZeJ1Fx"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, CountVectorizer\n",
        "from pyspark.sql.types import StringType,DoubleType,IntegerType,ArrayType\n",
        "#from pyspark.sql.functions import *\n",
        "from pyspark.ml.linalg import Vectors, SparseVector\n",
        "from pyspark.ml.clustering import LDA, BisectingKMeans\n",
        "from pyspark.sql.functions import monotonically_increasing_id\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHO9xo0_JPpt"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import codecs\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFHq6rlnJmed"
      },
      "outputs": [],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKxSznZPJ8iq"
      },
      "outputs": [],
      "source": [
        "# stopwords en nltk\n",
        "from nltk.corpus import stopwords\n",
        "stop_words_nltk = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMZSzEWVC6mK",
        "outputId": "b8cb439e-7062-4826-dd4f-6c61a57e8fd6"
      },
      "outputs": [],
      "source": [
        "df=spark.read.csv(\"gdrive/MyDrive/st1800-241/datasets/airlines.csv\", inferSchema=True, header=True)\n",
        "df = df.fillna({'review': ''})                               # Replace nulls with blank string\n",
        "\n",
        "# Add Unique ID\n",
        "df = df.withColumn(\"uid\", monotonically_increasing_id())     # Create Unique ID\n",
        "\n",
        "# Generate YYYY-MM variable\n",
        "df = df.withColumn(\"year_month\", df.date.substr(1,6))\n",
        "\n",
        "# Show rawdata (as DataFrame)\n",
        "df.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Gn79OUsC6mP",
        "outputId": "32c6942c-a8f2-4b88-d32f-dd273a3eddc7"
      },
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView(\"train_df\")\n",
        "sqlDF = spark.sql(\"SELECT * FROM train_df where cabin='Economy'\")\n",
        "sqlDF.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0gEwihnC6mS",
        "outputId": "72975215-486f-482e-f673-fa7fdfa2c97f"
      },
      "outputs": [],
      "source": [
        "df = df.select('id','review')\n",
        "df.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "au_sR-FTC6mW",
        "outputId": "f5cbfaf0-edaa-4392-9af9-bbea2497f900"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANxqRCPtC6md"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSZsEMHfC6mZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJwZvhXqC6mj",
        "outputId": "09b59a26-50c1-4f7d-d95b-1eab1d22d546"
      },
      "outputs": [],
      "source": [
        "################################################################################################\n",
        "#\n",
        "#   Text Pre-processing (consider using one or all of the following):\n",
        "#       - Remove common words (with stoplist)\n",
        "#       - Handle punctuation\n",
        "#       - lowcase/upcase\n",
        "#       - Stemming\n",
        "#       - Part-of-Speech Tagging (nouns, verbs, adj, etc.)\n",
        "#\n",
        "################################################################################################\n",
        "from pyspark.sql.functions import udf,struct\n",
        "#from pyspark.sql.types import StructType\n",
        "def textprep(record):\n",
        "    text  = record[1]\n",
        "    uid   = record[0]\n",
        "    tokens = text.split()\n",
        "       \n",
        "    # Custom List of Stopwords - Add your own here\n",
        "    tokens = [re.sub('[^a-zA-Z0-9]','',word) for word in tokens]                                       # Remove special characters\n",
        "    tokens = [word.lower() for word in tokens if len(word)>2 and word.lower() not in stop_words_nltk]     # Remove stopwords and words under X length\n",
        "    return tokens\n",
        "\n",
        "udf_textprep = udf(textprep , ArrayType(StringType()))\n",
        "df = df.withColumn(\"words\", udf_textprep(struct([df[x] for x in df.columns])))\n",
        "\n",
        "#tokenizer = Tokenizer(inputCol=\"description\", outputCol=\"words\")\n",
        "#wordsData = tokenizer.transform(text)\n",
        "df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZI9yaPmyC6mm",
        "outputId": "936e63b1-0771-4363-876b-3ae7764b05c3"
      },
      "outputs": [],
      "source": [
        "# Term Frequency Vectorization  - Option 1 (Using hashingTF): \n",
        "#hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\n",
        "#featurizedData = hashingTF.transform(clean_text)\n",
        "\n",
        "# Term Frequency Vectorization  - Option 2 (CountVectorizer)    : \n",
        "#cv = CountVectorizer(inputCol=\"words\", outputCol=\"rawFeatures\", vocabSize = 1000)\n",
        "cv = CountVectorizer(inputCol=\"words\", outputCol=\"rawFeatures\")\n",
        "cvmodel = cv.fit(df)\n",
        "featurizedData = cvmodel.transform(df)\n",
        "\n",
        "vocab = cvmodel.vocabulary\n",
        "vocab_broadcast = sc.broadcast(vocab)\n",
        "\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
        "idfModel = idf.fit(featurizedData)\n",
        "df = idfModel.transform(featurizedData)\n",
        "df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZaGGa0QC6mo",
        "outputId": "cd8d8475-d8df-4be5-9c9e-8c0085078cde"
      },
      "outputs": [],
      "source": [
        "# Generate 25 Data-Driven Topics:\n",
        "lda = LDA(k=25, seed=123, optimizer=\"em\", featuresCol=\"features\")\n",
        "\n",
        "ldamodel = lda.fit(df)\n",
        "\n",
        "#model.isDistributed()\n",
        "#model.vocabSize()\n",
        "\n",
        "ldatopics = ldamodel.describeTopics()\n",
        "#ldatopics.show(25)\n",
        "\n",
        "def map_termID_to_Word(termIndices):\n",
        "    words = []\n",
        "    for termID in termIndices:\n",
        "        words.append(vocab_broadcast.value[termID])\n",
        "    \n",
        "    return words\n",
        "\n",
        "udf_map_termID_to_Word = udf(map_termID_to_Word , ArrayType(StringType()))\n",
        "ldatopics_mapped = ldatopics.withColumn(\"topic_desc\", udf_map_termID_to_Word(ldatopics.termIndices))\n",
        "ldatopics_mapped.select(ldatopics_mapped.topic, ldatopics_mapped.topic_desc).show(50,False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PLOB_wdC6mr",
        "outputId": "06ceb311-0b14-40f1-abdc-e218a97388a6"
      },
      "outputs": [],
      "source": [
        "ldaResults = ldamodel.transform(df)\n",
        "\n",
        "ldaResults.select('words','features','topicDistribution').show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhwK6qgQIB0K",
        "outputId": "aa8c3b76-d88a-4850-e76e-323721e7ca77"
      },
      "outputs": [],
      "source": [
        "ldaResults.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h47VmTHYC6mv",
        "outputId": "f1b3b4d8-3445-4559-cc03-98ed7dda7f3a"
      },
      "outputs": [],
      "source": [
        "def maintop(record):\n",
        "    vectorlist = record.tolist()\n",
        "    m = max(vectorlist)\n",
        "    maintops = [i for i, j in enumerate(vectorlist) if j == m] \n",
        "    return maintops\n",
        "\n",
        "def sorttop(record):\n",
        "    vectorlist = record.tolist()\n",
        "    unsorted = [(i,j) for i,j in enumerate(vectorlist)]\n",
        "    maintops = [i for i,j in sorted(unsorted, key=lambda tup: -tup[1])]\n",
        "    return maintops[:5]\n",
        "\n",
        "def maintop2(record):\n",
        "    return record.tolist()\n",
        "\n",
        "udf_maintop = udf(maintop, ArrayType(DoubleType()))\n",
        "udf_maintop2 = udf(maintop2, ArrayType(DoubleType()))\n",
        "udf_maintop3 = udf(sorttop, ArrayType(IntegerType()))\n",
        "\n",
        "# Extract document weights for Topics 0 and 20\n",
        "enrichedData = ldaResults.withColumn(\"MainTopics\", udf_maintop3(ldaResults.topicDistribution))\n",
        "enrichedData = enrichedData.withColumn(\"MainTopic\", enrichedData.MainTopics[0])\n",
        "\n",
        "enrichedData.select('MainTopic','MainTopics').show(5,False)\n",
        "\n",
        "enrichedData.groupBy('MainTopic').count().sort('count', ascending=False).show()\n",
        "\n",
        "#enrichedData.agg(max(\"Topic_12\")).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vTYmNbjC6mz",
        "outputId": "1886cc17-19ad-4cb1-9f64-db900a4e1b64"
      },
      "outputs": [],
      "source": [
        "enrichedData.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "tp-airlines.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
